This is largely a replication of the methods in AlphaGo Zero but with a little twist. Instead of just predicting game winners, we explicitly use a form of Deep Q Learning called Deep Double-Q Learning.
This method has been shown to increase generalization of the network. 


This project was written for CS221 at Stanford.
A note for future Stanford students: Please do not use any of the code in this repo without attribution, that is against the Honor Code.
